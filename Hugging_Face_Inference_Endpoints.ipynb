{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlb-jlb/ML_Notebooks/blob/main/Hugging_Face_Inference_Endpoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3BsR0ktOVFo",
        "outputId": "43958e6f-e0ff-46f4-a7e3-0e66b7d4188c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/268.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m256.0/268.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.65.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4)\n",
            "Installing collected packages: huggingface_hub\n",
            "Successfully installed huggingface_hub-0.16.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -U huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# HF Inference Endpoints parameter\n",
        "endpoint_url = \"YOUR_ENDPOINT_URL\"\n",
        "hf_token = \"YOUR_HF_API_KEY\"\n",
        "\n",
        "# Streaming Client\n",
        "client = InferenceClient(endpoint_url, token=hf_token)\n",
        "\n",
        "# generation parameter\n",
        "gen_kwargs = dict(\n",
        "    max_new_tokens=512,\n",
        "    top_k=30,\n",
        "    top_p=0.9,\n",
        "    temperature=0.2,\n",
        "    repetition_penalty=1.02,\n",
        "    stop_sequences=[\"\\nUser:\", \"<|endoftext|>\", \"</s>\"],\n",
        ")"
      ],
      "metadata": {
        "id": "zDNzF_biO3VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Non-streaming Example"
      ],
      "metadata": {
        "id": "X5_PdgpVQRVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt\n",
        "prompt = \"What can you do in Nuremberg, Germany? Give me 3 Tips\"\n",
        "\n",
        "response = client.text_generation(prompt, **gen_kwargs)\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "sUX3b0IIPW10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed22f511-0108-47db-afa2-250ac9c01bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Visit the Nuremberg Castle, where the famous Nuremberg Rallies took place during the Nazi regime. 2. Explore the medieval old town, with cobblestone streets and historic architecture. 3. Try delicious German food at one of the local restaurants, such as wiener schnitzel or currywurst.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example with Streaming"
      ],
      "metadata": {
        "id": "73WXwNPCQUNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What can you do in Nuremberg, Germany? Give me 3 Tips\"\n",
        "\n",
        "stream = client.text_generation(prompt, stream=True, details=True, **gen_kwargs)\n",
        "\n",
        "# yield each generated token\n",
        "for r in stream:\n",
        "    # skip special tokens\n",
        "    if r.token.special:\n",
        "        continue\n",
        "    # stop if we encounter a stop sequence\n",
        "    if r.token.text in gen_kwargs[\"stop_sequences\"]:\n",
        "        break\n",
        "    # yield the generated token\n",
        "    print(r.token.text, end = \"\")\n",
        "    # yield r.token.text"
      ],
      "metadata": {
        "id": "-oJu0gagPFWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bb6cc4f-9022-4f28-d8ad-023964ac8beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1. Visit the Nuremberg Castle, which is home to the famous Christmas Market. 2. Explore the medieval streets and alleys of the city. 3. Try delicious German food at one of the many restaurants."
          ]
        }
      ]
    }
  ]
}